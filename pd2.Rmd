---
title: "Práctica dirigida 2"
output:
  html_document:
    toc: yes
    toc_float: yes
    collapsed: no
    number_sections: no
    toc_depth: 3
    theme: flatly
    highlight: textmate
    always_allow_html: yes
---

**FACULTAD DE CIENCIAS SOCIALES - PUCP**

Curso: SOC294 - Estadística para el análisis sociológico 2

Semestre 2025 - 1

# **1.Regresión múltiple**

**¿Para qué sirve hacer una regresión?**

-   Para identificar la relación entre variables de interés a través de un modelo (ecuación de la recta).

-   La ecuación nos sirve para la predicción.

-   El comportamiento de una variable está influencia normalmente por más de un factor, podemos obtener una mejor predicción añadiendo más variables.

**¿La relación entre las variables suele ser exacta?**

NO. La distancia de cada punto (valor observado) a la recta es la parte que el modelo no puede predecir. Lo que buscamos es encontrar un modelo (ecuación de la recta) en el cual los errores sean los mínimos posibles (Estimación de Mínimos Cuadrados - EMC)

Objetivo: Conocer el valor de una variable a partir de más de una variable explicativa.

Y′=β0+β1∗x1+β2∗x2+βi∗xi

En esta expresión, cada uno de los coeficientes representa la influencia individual que cada una de las X tiene sobre Y.

Es importante entender la lógica del control estadístico. En una regresión lineal múltiple, el control estadístico nos permite “eliminar” explicaciones alternativas, en tanto se aisla el efecto de otras variables. La idea es:

-   Evaluar si la relación entre X -- Y permanece si se remueve el efecto de otra variable, es decir, si se controla por una tercera variable.

-   Se analiza la relación entre X – Y para valores similares o iguales de una variable Z. De esta manera se elimina la influencia de Z en la relación entre X – Y. Es un paso en el establecimiento de X -\> Y.

-   Si la relación entre X - Y desaparece cuando se controla por Z, se dice que la relación era espúrea.

## Ejercicio práctico

Para este ejercicio utilizaremos la base de datos de indicadores sociodemográficos del mundo por quinquenios. La fuente original de los datos es el proyecto Gapminder.

Consideraremos las siguientes variables

Variable dependiente: Tasa global de fecundidad (tfr) Variables independientes: Años de escolaridad de la mujer (yearSchF) Tasa de uso de anticonceptivos (contracep)

Primero calcularemos dos modelos de regresión simple, que luego compararemos con un modelo de regresión múltiple. Trabajaremos primero con datos del quinquenio 1995-1999.

```{r}
load(url("https://www.dropbox.com/s/fyobx9uswy3qgp3/dataWorld_q.rda?dl=1"))
```

### Modelo 1 simple

```{r}
mod.reg1 <- lm(tfr ~ yearSchF, 
               data = dataWorld_q[dataWorld_q$quinq == "1995-1999", ])

summary(mod.reg1)
```

### Modelo 2 simple

```{r}

mod.reg2 <- lm(tfr ~ contracep, 
               data = dataWorld_q[dataWorld_q$quinq == "1995-1999", ])

summary(mod.reg2)
```

### Modelo 3 múltiple

```{r}
mod.reg3 <- lm(tfr ~ yearSchF +  contracep, 
               data = dataWorld_q[dataWorld_q$quinq == "1995-1999", ])

summary(mod.reg3)
```

### Utilización del stargazer

```{r}
library(stargazer)
stargazer(mod.reg1, mod.reg2, mod.reg3, type = "text",
          omit.stat=c("ser","f"), 
          title = "OLS para Tasa Global de Fecundidad 1995-1999",
          covariate.labels = c("Años de escolaridad mujeres", 
                               "% Uso de anticonceptivos"),
          dep.var.caption = "Variable dependiente:",
          dep.var.labels   = "Fecundidad",
          star.cutoffs = c(0.05, 0.01, 0.001))
```

## R2 ajustado

Corrige el R2 penalizando por el número de predictores.

Se usa cuando tienes más de una variable independiente para evitar un sobreajuste.

Si agregas variables irrelevantes, R2 ajustado puede disminuir. Si las variables nuevas realmente ayudan, R2 ajustado aumenta.

## Estimando valores de la variable dependiente (Y)

### ¿Qué pasa si los años de escolaridad son 11 y el uso de anticonceptivos 50?

```{r}
new.data1 <- data.frame(yearSchF = c(11), contracep = 50)
predict(mod.reg3, newdata = new.data1)
```

### ¿Si los años de escolaridad aumentan en +1?, ¿en +10?

```{r}
new.data2 <- data.frame(yearSchF = c(11,12,21), contracep = 50)
predict(mod.reg3, newdata = new.data2)
```

### ¿Si el uso de anticonceptivos se incrementa en 10%?

```{r}
new.data3 <- data.frame(yearSchF = c(11), contracep = c(50, 60, 70))
predict(mod.reg3, newdata = new.data3)
```

## Modelo con 3 variables independientes

Se incluye el ingreso per cápita, transformado en escala logarítmica de base 10:

```{r}
mod.reg4 <- lm(tfr ~ yearSchF +  contracep + log10(incomePp), 
               data = dataWorld_q[dataWorld_q$quinq == "1995-1999", ])

summary(mod.reg4)
```

## Coeficiente estandarizado o coeficientes beta

Los coeficientes estandarizados (también llamados coeficientes beta o beta estandarizados) son una versión de los coeficientes de regresión en la que todas las variables han sido transformadas a la misma escala, generalmente con media 0 y desviación estándar 1. Se pueden comparar directamente entre sí, ya que están en la misma escala.

```{r}
library(psych)
data95 <- subset(dataWorld_q, dataWorld_q$quinq == "1995-1999")

describe(data95[, c(3,4,5)], fast=T)
```

```{r}
library(lm.beta)

lm.beta(mod.reg3)
```

# **2.Regresión con variables categóricas**

En un modelo de regresión múltiple de mínimos cuadrados ordinarios (OLS), la variable dependiente es una variable numérica o cuantitativa. Sin embargo, las variables independientes pueden ser tanto numéricas como categóricas.

Las variables categóricas pueden ser:

Dicotómicas: Solo tienen dos categorías (Sexo del entrevistado; ocurre o no un evento; una condición es verdadera o falsa; etc.) Politómicas: Tienen tres o más categorías (región Costa, Sierra, Selva, por ejemplo) Cuando se incluye una variable categórica en un modelo de regresión, se la representa a través de una o más “dummy variables”, dependiendo del número de categorías que tenga.

## Ejercicio práctico

Ingreso mensual de trabajadores dependientes

Para explorar este tema, vamos a utilizar la información del Módulo 5 de la ENAHO 2017 sobre empleo e ingresos de los miembros del hogar. Específicamente utilizaremos los datos correspondientes a la ocupación principal de los trabajadores dependientes.

En este ejemplo, tomaremos como variable depediente (Y) el ingreso mensual bruto del trabajador dependiente en su ocupación principal. Nuestra primera variable independiente será el nivel educativo del trabajador.

**Diccionario**

**NiveEdu "¿Cuál es el último año o grado de estudios y nivel que aprobó? - Nivel**

0\. Sin Nivel

1\. Inicial

2\. Primaria Incompleta

3\. Primaria Completa

4\. Secundaria Incompleta

5\. Secundaria Completa

6\. Superior No Universitaria Incompleta

7\. Superior No Universitaria Completa

8\. Superior Universitaria Incompleta

9\. Superior Universitaria Completa

10\. Maestria/Doctorado"

**Ocup "Ud. se desempeño en su ocupación principal o negocio como:**

1\. Empleador o patrono

2\. Trabajador Independiente

3\. Empleado

4\. Obrero

5\. Trabajador Familiar No Remunerado

6\. Trabajador del Hogar

7\. Otro"

**Dominio**

-   Costa

-   Sierra

-   Selva

-   Lima M

**Ingreso**

-   Ingreso mensual en términos brutos

**Sexo**

-   Hombre

-   Mujer

```{r}
#library(dplyr)
#data <- Enaho01a_2023_500 %>% select(1:9, 39, 1021, 1024, 101, 102, 1393)

#colnames(data)[c(10, 11, 12, 13, 14, 15)] <- c("Ocup", "Sexo", "NiveEdu", "FreqPag", "Ingreso", "HorasTrabj")

#data <- filter(data, Ocup %in% c(3, 4, 6))
#data <- filter(data, NiveEdu %in% c(1:11))
#data <- filter(data, data$FreqPag == 4)

#data <- data %>%
#  mutate(DOMINIO = case_when(
# DOMINIO %in% c(1, 2, 3) ~ "Costa",
# DOMINIO %in% c(4, 5, 6) ~ "Sierra",
# DOMINIO == 7 ~ "Selva",
# DOMINIO == 8 ~ "Lima M"
#))

#data <- data %>%
#mutate(Sexo = case_when(
#  Sexo == 1 ~ "Hombre",
#  Sexo == 2 ~ "Mujer"
#))

#data$NiveEdu <- ifelse(data$NiveEdu >= 1 & data$NiveEdu <= 11, data$NiveEdu - 1, data$NiveEdu)

#data <- na.omit(data)

#write.csv(data, "Empleo.csv", row.names = FALSE)

library(rio)
data=import("Empleo.csv")
```

```{r}
library(ggplot2)
p <- ggplot(data, aes(x = Ingreso)) + 
  geom_histogram(aes(y = ..density..), colour = "black", fill = "white") + 
  geom_density(alpha = .2, fill = "#FF6666") +
  scale_x_continuous(limits = c(0, 10000))

p
```

### Modelo 1.0

*Ingreso = b0 + b1\*NiveEdu*

```{r}
mod1.0 <- lm(Ingreso ~ NiveEdu, data = data)
stargazer(mod1.0, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

### Modelo 1.1

#### **Incluyendo una variable dicotómica en el modelo de regresión (1)**

En el diagrama anterior se observa que los puntos rojos, que represetan a los hombres, son más frecuentes encima de la recta de regresión que por debajo de ella, lo que indicaría que los hombres tienden a tener ingresos mayores a los de las mujeres.

Vamos a introducir en el modelo al sexo como una variable categórica - dicotómica con efecto independiente aditivo:

*Ingreso = b0 + b1NiveEdu + b2Sexo*

En este caso, la variable sexo será procesada de la siguiente manera: sexo=0: Hombres; sexo=1: Mujeres.

#### **Incluyendo una variable dicotómica en el modelo de regresión (2)**

En tal sentido si el trabajador es un hombre (sexo=0), el modelo de regresión sería:

*Ingreso = b0 + b1NiveEdu + b2\*1*

Por otro lado si el trabajador es una mujer (sexo=1sexo=1), entonces el modelo de regresión sería:

*Ingreso = b0 + b1NiveEdu + b2\*1*

Como se aprecia, en este caso, la variable sexo afecta la intersección del modelo.

```{r}
mod1.1 <- lm(Ingreso ~ NiveEdu + Sexo, data = data)
stargazer(mod1.0, mod1.1, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

### Modelo 1.2

```{r}
mod1.2 <- lm(Ingreso ~ NiveEdu + HorasTrabj, data = data)
stargazer(mod1.0, mod1.1, mod1.2, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

### Modelo 1.3

#### **Modelo con variables politómicas (1)**

```{r}
mod1.3 <- lm(Ingreso ~ NiveEdu + DOMINIO, data = data)
stargazer(mod1.0, mod1.1, mod1.2, mod1.3, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

### Modelo 1.4

```{r}
mod1.4 <- lm(Ingreso ~ NiveEdu + DOMINIO + Sexo, data = data)
stargazer(mod1.0, mod1.1, mod1.2, mod1.3, mod1.4, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

## Modelo para una variable categórica con efecto interactivo

Supongamos que en vez de proponer que la variable sexo tiene un efecto aditivo en el ingreso, independiente respecto del nivel educativo, trabajemos con la hipótesis de que existe una interacción entre la variable sexo y el nivel educativo.

En este segundo caso, la hipótesis plantea que el efecto de la educación en el ingreso será diferente según el sexo del trabajador, por lo tanto el coeficiente de la variable categórica afectaría la pendiente en vez de la constante de la ecuación.

Ecuaciones para efectos independientes e interactivos En el caso de un efecto independiente, la ecuación que ya hemos visto es:

*Ingreso=b0+b1NiveEdu+b2Sexo*

-   *Hombres (sexo=0): Ingreso=b0+b1NiveEdu*

-   *Mujeres (sexo=1): Ingreso=(b0+b2)+b1NiveEdu*

En el caso de un efecto interactivo, la ecuación sería:

*Ingreso=b0+b1nivedu+b2sexo∗NiveEdu*

-   *Hombres (sexo=0): Ingreso=b0+b1NiveEdu*

-   *Mujeres (sexo=1): Ingreso=b0+(b1+b2)NiveEdu*

### Modelo 1.5

```{r}
mod1.5 <- lm(Ingreso ~ NiveEdu : Sexo, data = data)
stargazer(mod1.0, mod1.1, mod1.5, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

```{r}
fit1.5 <- predict(mod1.5)
dataf5 <- cbind(data, fit1.5)
ggplot(dataf5, aes(x = NiveEdu, y = Ingreso, color = Sexo)) +
  geom_point() + 
  geom_line(aes(y = fit1.5)) + 
  coord_cartesian(ylim = c(-400, 5000))
```

### Modelo 1.6

Podemos estimar otro modelo de regresión que contenga ambos supuestos.

-   Supuesto de efecto independiente: independientemente del nivel educativo, los hombres y las mujeres parten de distintas bases de ingreso, menores en el caso de las mujeres. Aquí tendremos dos intersecciones.

-   Supuesto de efecto interactivo: el efecto de la educación en los ingresos no es el mismo en el caso de los hombres y las mujeres. Las pendientes de hombres y mujeres serán distintas.

Ingreso=b0+b1NiveEdy+b2Sexo+b3Sexo∗Nivedu

```{r}
mod1.6 <- lm(Ingreso ~ NiveEdu * Sexo, data = data)
stargazer(mod1.0, mod1.1, mod1.5, mod1.6, type = "text",
          omit.stat=c("ser","f"), 
          model.numbers = FALSE, object.names = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

```{r}
fit1.6 <- predict(mod1.6)
dataf6 <- cbind(data, fit1.6)
ggplot(dataf6, aes(x = NiveEdu, y = Ingreso, color = Sexo)) +
  geom_point() + 
  geom_line(aes(y = fit1.6)) + 
  coord_cartesian(ylim = c(-400, 5000))
```
